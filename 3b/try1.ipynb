{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","import gc\n","import cv2\n","from PIL import Image\n","import random\n","import torch\n","\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","metadata":{},"source":["#### Data extraction"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["# There are two folders named Bikes and Horse in the path_name\n","# this method reads the data from each category folder and splits the data for each category in train and test based on the train_ratio parameter.\n","\n","def extract_data(path_name, categories, train_ratio=0.9):\n","    path = path_name\n","    data = []\n","    im_w = 224\n","    im_h = 224\n","    # categories = ['Bikes', 'Horses']\n","    for x in range(len(categories)):\n","        cat = categories[x]\n","        cat_data = []\n","        sub_path = os.path.join(path, cat)\n","        for filename in os.listdir(sub_path):\n","            img_path = os.path.join(sub_path, filename)\n","            imag = cv2.imread(img_path)\n","            img_from_ar = Image.fromarray(imag, 'RGB')\n","            resized_image = img_from_ar.resize((im_w, im_h))\n","            cat_data.append([np.array(resized_image), x])\n","\n","        # Split data into train and test for this category\n","        split_index = int(len(cat_data) * train_ratio)\n","        random.shuffle(cat_data)\n","        train_data = cat_data[:split_index]\n","        test_data = cat_data[split_index:]\n","        data.extend(train_data)\n","        data.extend(test_data)\n","    random.shuffle(data)  # Shuffle the data\n","    return data\n","\n","train_ratio = 0.9  # Adjust this ratio as desired\n","path_name = \"./Assignment2_BikeHorses/\"\n","categories = ['Bikes', 'Horses']\n","\n","# path_name = \"./Fish_Dataset/\"\n","# categories = ['Black_Sea_Sprat', 'Gilt_Head_Bream', 'Hourse_Mackerel', 'Red_Mullet', 'Red_Sea_Bream', 'Sea_Bass', 'Shrimp', 'Striped_Red_Mullet', 'Trout']\n","data = extract_data(path_name, categories, train_ratio)\n","\n","# Split data into train and test\n","split_index = int(len(data) * train_ratio)\n","train = data[:split_index]\n","test = data[split_index:]"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the pretrained alexnet model and fix the parameters for each layer"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /home/ricky/.cache/torch/hub/pytorch_vision_v0.6.0\n","/home/ricky/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/ricky/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["from torchvision.models import alexnet\n","# Load the pretrained AlexNet model\n","net = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained = True)\n","\n","for params in net.parameters():\n","    params.requires_grad=False\n","net.eval()"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["# Replace last layer of the pretrained network with new layer so that they can be finetuned to get better results.\n","# Add an extra linear layer from 1000 input to 2 out_features and then a softmax layer.\n","\n","net.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=1000, bias=True)\n","net = torch.nn.Sequential(net,torch.nn.Linear(in_features=1000,out_features=len(categories),bias=True),torch.nn.Softmax(dim=1))"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["# For transformation of training set do randomHorizontalFlip to make the model more genralized.\n","import torchvision.transforms as transforms\n","\n","# Normalize training set together with augmentation\n","transform_train = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n","])\n","\n","# Normalize test set same as training set without augmentation\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n","])\n","\n","batch_size=16"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class ImageDataset(Dataset):\n","    def __init__(self,dataset):\n","        self.dataset = dataset\n","    def __len__(self):\n","        return len(self.dataset)\n","    def __getitem__(self, idx):\n","        return self.dataset[idx]\n","\n","trainset = ImageDataset(train)\n","testset = ImageDataset(test)"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","def generate_batch(batch):\n","    images = [x[0] for x in batch]  # Extract images from the batch\n","    labels = [x[1] for x in batch]  # Extract labels from the batch\n","    \n","    # Convert images to tensors and apply transformations\n","    images = torch.stack([transform(x) for x in images])\n","    labels = torch.tensor(labels, dtype=torch.long)\n","    \n","    return images, labels\n","\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2,collate_fn = generate_batch)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2,collate_fn = generate_batch)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]},{"data":{"text/plain":["CrossEntropyLoss()"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","# Using CrossEntropy loss as we are handling classification problem\n","# usig momentum method for optimization\n","\n","optimizer = optim.SGD(net.parameters(),lr = 0.001,momentum = 0.9)      \n","criterion = nn.CrossEntropyLoss()           \n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","net.to(device)\n","criterion.to(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Epoch done\n","1 Epoch done\n","2 Epoch done\n","3 Epoch done\n","4 Epoch done\n","5 Epoch done\n","6 Epoch done\n","7 Epoch done\n","8 Epoch done\n","9 Epoch done\n","10 Epoch done\n","11 Epoch done\n","12 Epoch done\n","13 Epoch done\n","14 Epoch done\n","15 Epoch done\n","16 Epoch done\n","17 Epoch done\n","18 Epoch done\n","19 Epoch done\n","20 Epoch done\n","21 Epoch done\n","22 Epoch done\n","23 Epoch done\n","24 Epoch done\n"]}],"source":["import matplotlib.pyplot as plt\n","train_losses = []\n","validation_losses = []\n","for epoch in range(20):  # loop over the dataset multiple times\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)  # get the inputs; data is a list of [inputs, labels]\n","        optimizer.zero_grad()  # zero the parameter gradients\n","        outputs = net(inputs)\n","        loss = criterion(outputs,labels)\n","        loss.backward()\n","        optimizer.step()\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","\n","    train_losses.append((running_loss*32)/len(trainloader))\n","    running_loss = 0.0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images,labels = images.to(device),labels.to(device)\n","            outputs = net(images)\n","            loss = criterion(outputs,labels)\n","            running_loss += loss.item()\n","    validation_losses.append((running_loss*32)/len(testloader))\n","    print(\"{} Epoch done\".format(epoch))"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Finished Training\n"]},{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7f8b749e6520>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["print('Finished Training')\n","plt.plot(train_losses,label = 'train')\n","plt.legend()"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7f8b7643faf0>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.plot(validation_losses,label = 'validation')\n","plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["## Store the fine tuned network.\n","This can and will be later used for extracting features and then various methods like support vector machine or linear regression can be applied on it to get different models for classification."]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["PATH = './alexnet_fine_tuned.pth'\n","torch.save(net.state_dict(), PATH)\n","temp_net = net"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["PATH = './alexnet_fine_tuned.pth'\n","# net = Net()\n","net.load_state_dict(torch.load(PATH))\n","temp_net = net"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["net = net[:-2]"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["def make_data(dataloader):\n","    train_features,train_labels = [],[]\n","    with torch.no_grad():\n","        for data in dataloader:\n","            images, labels = data\n","            images,labels = images.to(device),labels.to(device)\n","            output = net(images)\n","            train_features.extend(output)\n","            train_labels.extend(labels)\n","    return train_features,train_labels"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["device1 = torch.device('cpu')"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["train_features,train_labels = make_data(trainloader)"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["test_features,test_labels = make_data(testloader)"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[],"source":["training_data = [t.to(device1).numpy() for t in train_features]\n","labels = [t.to(device1).numpy() for t in train_labels]\n","testing_data = [t.to(device1).numpy() for t in train_features]\n","test_labels = [t.to(device1).numpy() for t in train_labels]"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[],"source":["training_data,labels = pd.DataFrame(training_data),pd.DataFrame(labels)"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[],"source":["testing_data,testing_labels = pd.DataFrame(testing_data),pd.DataFrame(test_labels)"]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[],"source":["training_data.to_csv('./training_data.csv',index=False)\n","labels.to_csv('./labels.csv',index=False)\n","testing_data.to_csv('./testing_data.csv',index=False)\n","testing_labels.to_csv('./test_labels.csv',index=False)"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["train = pd.concat([training_data,testing_data])\n","y = pd.concat([labels,testing_labels])"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train,y_test = train_test_split(train,y,shuffle=True,random_state=2021,test_size=0.1)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(33, 1)\n"]}],"source":["print(y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["###  Applying support vector machine model on the extracted features"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ricky/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["SVC(kernel='linear')"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.svm import SVC\n","\n","svc = SVC(kernel='linear')\n","svc.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["from sklearn.metrics import accuracy_score\n","\n","y_pred = svc.predict(X_test)\n","print(accuracy_score(y_test,y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["#### Applying logistic regression on the extracted features for classification"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ricky/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n","  warnings.warn(\n","/home/ricky/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(l1_ratio=0, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(l1_ratio=0, max_iter=1000)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(l1_ratio=0, max_iter=1000)"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression(max_iter = 1000,l1_ratio=0)\n","lr.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["from sklearn.metrics import accuracy_score\n","\n","y_pred = lr.predict(X_test)\n","print(accuracy_score(y_test,y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["#### Applying KNN clustering on the extracted features for classification"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ricky/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy: 1.0\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","knn = KNeighborsClassifier(n_neighbors=5)\n","knn.fit(X_train, y_train)\n","\n","y_pred = knn.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
